This repo contains code for the Nova Science coding group.

This [online book](https://d2l.ai/) is quickly becoming the standard text 
for Deep Learning.

And here is [repo](https://github.com/n2cholas/awesome-jax) with list of projects in JAX. 

## Notebooks available

The mnist.ipynb notebook builds a simple MNIST classifier in JAX. Here is a Google Colab [version](https://drive.google.com/file/d/1BC1wEJzWNIVZipLcmEBGOozb5aQ0uXHN/view?usp=sharing). And for a classification over 99.5% please consult the Jiucheng branch.

The rng.ipynb notebook explains Pseudo Random Number Generation in JAX. Here is a Google Colab [version](https://drive.google.com/file/d/1gXnED5oyTWUazb_z4oJroB54vngdZ6mn/view?usp=sharing).

The autodiff.ipynb looks of examples of how autodiff is used in JAX. Here is a Google Colab [version](https://colab.research.google.com/drive/1ITvjHj_2ykypuAWumTIAwBO28dZ-tUij?usp=sharing).

The pytrees.ipynb looks at structure and utilities for pytrees. Here is a Google Colab [version](https://colab.research.google.com/drive/1PuSNaXscZC7joS4cxl6IqWg6jsNOdWMg?usp=sharing). 

The state.ipynb notebook investigates how program state is handled in purely functional JAX. Here is the Colab [version](https://colab.research.google.com/drive/1ixnTRFpWp_-x7GAfJO3c5cVkNLMw62jj?usp=sharing).

The jtransform.ipynb notebook investigates how JAX tranforms functions based on their intermediate langage *jaxpr* representations. Here is the Colab [version](https://drive.google.com/file/d/1pW7npFTBEom9a_R-qtXghH1syhRkuLjy/view?usp=sharing).
